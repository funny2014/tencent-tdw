query: drop table nzhang_ctas1
query: drop table nzhang_ctas2
query: drop table nzhang_ctas3
query: explain create table nzhang_ctas1 as select key k, value from src sort by k, value limit 10
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE nzhang_ctas1 TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key) k) (TOK_SELEXPR (TOK_TABLE_OR_COL value))) (TOK_SORTBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL k)) (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value))) (TOK_LIMIT 10))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1;
  Stage-0
    type:;depends on:Stage-2;
  Stage-3
    type:;depends on:Stage-0;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        default_db/src 
          Operator:          TableScan
            alias: default_db/src
            Operator:            Select Operator
              expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
              outputColumnNames: _col0, _col1
              Operator:              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: ++
                output key names: reducesinkkey0, reducesinkkey1
                output value names: _col0, _col1
                tag: -1
                value expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
      Path -> Alias:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/src [default_db/src]
      Reduce Operator Tree:
        Operator:        Extract
          Operator:          Limit
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/1392266447/10002 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: ++
              output key names: reducesinkkey0, reducesinkkey1
              output value names: _col0, _col1
              tag: -1
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
      Path -> Alias:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/1392266447/10002 [file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/1392266447/10002]
      Reduce Operator Tree:
        Operator:        Extract
          Operator:          Limit
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
          destination: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/nzhang_ctas1

  Stage: Stage-3
      Create Table Operator:
        Create Table
          columns: k string, value string
          if compressed: false
          if not exists: false
          input format: org.apache.hadoop.mapred.TextInputFormat
          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          name: nzhang_ctas1
          isExternal: false

query: create table nzhang_ctas1 as select key k, value from src sort by k, value limit 10
query: select * from nzhang_ctas1
Input: default_db/nzhang_ctas1
Output: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/918971429/10000
0	val_0
0	val_0
0	val_0
10	val_10
100	val_100
100	val_100
103	val_103
103	val_103
104	val_104
104	val_104
query: explain create table nzhang_ctas2 as select * from src sort by key, value limit 10
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE nzhang_ctas2 TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_SORTBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL key)) (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value))) (TOK_LIMIT 10))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1;
  Stage-0
    type:;depends on:Stage-2;
  Stage-3
    type:;depends on:Stage-0;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        default_db/src 
          Operator:          TableScan
            alias: default_db/src
            Operator:            Select Operator
              expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
              outputColumnNames: _col0, _col1
              Operator:              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: ++
                output key names: reducesinkkey0, reducesinkkey1
                output value names: _col0, _col1
                tag: -1
                value expressions:
                      expr: _col0
                      type: string
                      expr: _col1
                      type: string
      Path -> Alias:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/src [default_db/src]
      Reduce Operator Tree:
        Operator:        Extract
          Operator:          Limit
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/361139340/10002 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: ++
              output key names: reducesinkkey0, reducesinkkey1
              output value names: _col0, _col1
              tag: -1
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
      Path -> Alias:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/361139340/10002 [file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/361139340/10002]
      Reduce Operator Tree:
        Operator:        Extract
          Operator:          Limit
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
          destination: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/nzhang_ctas2

  Stage: Stage-3
      Create Table Operator:
        Create Table
          columns: key string, value string
          if compressed: false
          if not exists: false
          input format: org.apache.hadoop.mapred.TextInputFormat
          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          name: nzhang_ctas2
          isExternal: false

query: create table nzhang_ctas2 as select * from src sort by key, value limit 10
query: select * from nzhang_ctas2
Input: default_db/nzhang_ctas2
Output: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/453716260/10000
0	val_0
0	val_0
0	val_0
10	val_10
100	val_100
100	val_100
103	val_103
103	val_103
104	val_104
104	val_104
query: explain create table nzhang_ctas3 row format serde "org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe" stored as RCFile as select key/2 half_key, concat(value, "_con") conb  from src sort by half_key, conb limit 10
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE nzhang_ctas3 TOK_LIKETABLE TOK_TBLRCFILE (TOK_TABLESERIALIZER (TOK_SERDENAME "org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe")) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (/ (TOK_TABLE_OR_COL key) 2) half_key) (TOK_SELEXPR (TOK_FUNCTION concat (TOK_TABLE_OR_COL value) "_con") conb)) (TOK_SORTBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL half_key)) (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL conb))) (TOK_LIMIT 10))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1;
  Stage-0
    type:;depends on:Stage-2;
  Stage-3
    type:;depends on:Stage-0;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        default_db/src 
          Operator:          TableScan
            alias: default_db/src
            Operator:            Select Operator
              expressions:
                    expr: (key / 2)
                    type: double
                    expr: concat(value, '_con')
                    type: string
              outputColumnNames: _col0, _col1
              Operator:              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: double
                      expr: _col1
                      type: string
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: ++
                output key names: reducesinkkey0, reducesinkkey1
                output value names: _col0, _col1
                tag: -1
                value expressions:
                      expr: _col0
                      type: double
                      expr: _col1
                      type: string
      Path -> Alias:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/src [default_db/src]
      Reduce Operator Tree:
        Operator:        Extract
          Operator:          Limit
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/525336483/10002 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: double
                    expr: _col1
                    type: string
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: ++
              output key names: reducesinkkey0, reducesinkkey1
              output value names: _col0, _col1
              tag: -1
              value expressions:
                    expr: _col0
                    type: double
                    expr: _col1
                    type: string
      Path -> Alias:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/525336483/10002 [file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/525336483/10002]
      Reduce Operator Tree:
        Operator:        Extract
          Operator:          Limit
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
          destination: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/nzhang_ctas3

  Stage: Stage-3
      Create Table Operator:
        Create Table
          columns: half_key double, conb string
          if compressed: false
          if not exists: false
          input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
          serde name: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
          name: nzhang_ctas3
          isExternal: false

query: create table nzhang_ctas3 row format serde "org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe" stored as RCFile as select key/2 half_key, concat(value, "_con") conb  from src sort by half_key, conb limit 10
query: select * from nzhang_ctas3
Input: default_db/nzhang_ctas3
Output: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/1057503346/10000
0.0	val_0_con
0.0	val_0_con
0.0	val_0_con
1.0	val_2_con
2.0	val_4_con
2.5	val_5_con
2.5	val_5_con
2.5	val_5_con
4.0	val_8_con
4.5	val_9_con
query: explain create table if not exists nzhang_ctas3 as select key, value from src sort by key, value limit 2
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE nzhang_ctas3 TOK_IFNOTEXISTS TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value))) (TOK_SORTBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL key)) (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value))) (TOK_LIMIT 2))))

STAGE DEPENDENCIES:

STAGE PLANS:
query: create table if not exists nzhang_ctas3 as select key, value from src sort by key, value limit 2
query: select * from nzhang_ctas3
Input: default_db/nzhang_ctas3
Output: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/195553345/10000
0.0	val_0_con
0.0	val_0_con
0.0	val_0_con
1.0	val_2_con
2.0	val_4_con
2.5	val_5_con
2.5	val_5_con
2.5	val_5_con
4.0	val_8_con
4.5	val_9_con
query: drop table nzhang_ctas1
query: drop table nzhang_ctas2
query: drop table nzhang_ctas3
query: drop table nzhang_ctas3
query: drop table nzhang_ctas3
query: drop table nzhang_ctas3
query: drop table nzhang_ctas3
query: drop table nzhang_ctas3
query: drop table nzhang_ctas3
query: drop table nzhang_ctas3
query: drop table nzhang_ctas3
