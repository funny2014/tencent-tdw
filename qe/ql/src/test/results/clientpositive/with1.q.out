query: drop table test_with_1
query: CREATE TABLE test_with_1(
    i INT,
    b BIGINT,
    d DOUBLE
)
query: drop table test_with_2
query: CREATE TABLE test_with_2(
    i INT,
    b BIGINT,
    d DOUBLE
)
query: drop table test_with_3
query: CREATE TABLE test_with_3(
    i INT,
    b BIGINT,
    d DOUBLE
)
query: insert into test_with_1 values(1,1,1),(2,2,2),(3,3,3),(null,4,4),(5,null,null)
Output: default_db/test_with_1
query: insert into test_with_2 values(1,12,1),(42,2,2),(3,23,13),(null,14,4),(5,null,null)
Output: default_db/test_with_2
query: insert into test_with_3 values(1,1,11),(12,2,2),(73,3,3),(null,4,4),(15,null,null)
Output: default_db/test_with_3
query: explain with a as (select * from test_with_1) select a.i from a
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) i)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-0
    type:root stage;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
              outputColumnNames: _col0
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: int
                outputColumnNames: _col0
                Operator:                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                    table descs
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [a:default_db/test_with_1]

  Stage: Stage-0
    Fetch Operator
      limit: -1

query: with a as (select * from test_with_1) select a.i from a
Output: file:/data/allison/tdw_src/src/qe/build/ql/tmp/423599949/10000
1
2
3
NULL
5
query: explain with a as (select * from test_with_1),bb as (select i,b  from test_with_2),c as (select i,d,b from test_with_3) select a.i,bb.b,c.d from a,bb,c
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_JOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_2))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b))))) bb)) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_3))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL d)) (TOK_SELEXPR (TOK_TABLE_OR_COL b))))) c))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL c) d)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1;
  Stage-0
    type:root stage;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
              outputColumnNames: _col0
              Operator:              Reduce Output Operator
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: 
                output value names: _col0
                tag: 0
                value expressions:
                      expr: _col0
                      type: int
        bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Select Operator
              expressions:
                    expr: b
                    type: bigint
              outputColumnNames: _col1
              Operator:              Reduce Output Operator
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: 
                output value names: _col1
                tag: 1
                value expressions:
                      expr: _col1
                      type: bigint
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [a:default_db/test_with_1]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0}
            1 {VALUE._col1}
          handleSkewJoin: false
          outputColumnNames: _col0, _col4
          Operator:          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
              table descs
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              output value names: _col0, _col4
              tag: 0
              value expressions:
                    expr: _col0
                    type: int
                    expr: _col4
                    type: bigint
        c:default_db/test_with_3 
          Operator:          TableScan
            alias: default_db/test_with_3
            Operator:            Select Operator
              expressions:
                    expr: d
                    type: double
              outputColumnNames: _col1
              Operator:              Reduce Output Operator
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: 
                output value names: _col1
                tag: 1
                value expressions:
                      expr: _col1
                      type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/326230734/10002 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_3 [c:default_db/test_with_3]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col4}
            1 {VALUE._col1}
          handleSkewJoin: false
          outputColumnNames: _col0, _col4, _col6
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col4
                  type: bigint
                  expr: _col6
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1

query: with a as (select * from test_with_1),bb as (select i,b  from test_with_2),c as (select i,d,b from test_with_3) select a.i,bb.b,c.d from a,bb,c
Output: file:/data/allison/tdw_src/src/qe/build/ql/tmp/1954211726/10000
1	12	NULL
1	12	4.0
1	12	3.0
1	12	2.0
1	12	11.0
1	2	NULL
1	2	4.0
1	2	3.0
1	2	2.0
1	2	11.0
1	23	NULL
1	23	4.0
1	23	3.0
1	23	2.0
1	23	11.0
1	14	NULL
1	14	4.0
1	14	3.0
1	14	2.0
1	14	11.0
1	NULL	NULL
1	NULL	4.0
1	NULL	3.0
1	NULL	2.0
1	NULL	11.0
2	12	NULL
2	12	4.0
2	12	3.0
2	12	2.0
2	12	11.0
2	2	NULL
2	2	4.0
2	2	3.0
2	2	2.0
2	2	11.0
2	23	NULL
2	23	4.0
2	23	3.0
2	23	2.0
2	23	11.0
2	14	NULL
2	14	4.0
2	14	3.0
2	14	2.0
2	14	11.0
2	NULL	NULL
2	NULL	4.0
2	NULL	3.0
2	NULL	2.0
2	NULL	11.0
3	12	NULL
3	12	4.0
3	12	3.0
3	12	2.0
3	12	11.0
3	2	NULL
3	2	4.0
3	2	3.0
3	2	2.0
3	2	11.0
3	23	NULL
3	23	4.0
3	23	3.0
3	23	2.0
3	23	11.0
3	14	NULL
3	14	4.0
3	14	3.0
3	14	2.0
3	14	11.0
3	NULL	NULL
3	NULL	4.0
3	NULL	3.0
3	NULL	2.0
3	NULL	11.0
NULL	12	NULL
NULL	12	4.0
NULL	12	3.0
NULL	12	2.0
NULL	12	11.0
NULL	2	NULL
NULL	2	4.0
NULL	2	3.0
NULL	2	2.0
NULL	2	11.0
NULL	23	NULL
NULL	23	4.0
NULL	23	3.0
NULL	23	2.0
NULL	23	11.0
NULL	14	NULL
NULL	14	4.0
NULL	14	3.0
NULL	14	2.0
NULL	14	11.0
NULL	NULL	NULL
NULL	NULL	4.0
NULL	NULL	3.0
NULL	NULL	2.0
NULL	NULL	11.0
5	12	NULL
5	12	4.0
5	12	3.0
5	12	2.0
5	12	11.0
5	2	NULL
5	2	4.0
5	2	3.0
5	2	2.0
5	2	11.0
5	23	NULL
5	23	4.0
5	23	3.0
5	23	2.0
5	23	11.0
5	14	NULL
5	14	4.0
5	14	3.0
5	14	2.0
5	14	11.0
5	NULL	NULL
5	NULL	4.0
5	NULL	3.0
5	NULL	2.0
5	NULL	11.0
query: explain with a as (select * from test_with_1),bb as (select i,b,d  from test_with_2)  select a.b,a.d,a.i from a where not exists (select * from bb where bb.i=a.i)
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_LEFTOUTERJOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_2))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) bb) (= (. (TOK_TABLE_OR_COL bb) i) (. (TOK_TABLE_OR_COL a) i)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) d)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) i))) (TOK_WHERE (TOK_FUNCTION TOK_ISNULL (. (TOK_TABLE_OR_COL bb) i)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-0
    type:root stage;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: int
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: +
                output key names: reducesinkkey0
                output value names: _col0, _col1, _col2
                Map-reduce partition columns:
                      expr: _col0
                      type: int
                tag: 0
                value expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: bigint
                      expr: _col2
                      type: double
        bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
              outputColumnNames: _col0
              Operator:              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: int
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: +
                output key names: reducesinkkey0
                output value names: _col0
                Map-reduce partition columns:
                      expr: _col0
                      type: int
                tag: 1
                value expressions:
                      expr: _col0
                      type: int
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [a:default_db/test_with_1]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Left Outer Join0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2, _col3
          Operator:          Filter Operator
            predicate:
                expr: _col3 is null
                type: boolean
            Operator:            Select Operator
              expressions:
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
                    expr: _col0
                    type: int
              outputColumnNames: _col0, _col1, _col2
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1

query: with a as (select * from test_with_1),bb as (select i,b,d  from test_with_2)  select a.b,a.d,a.i from a where not exists (select * from bb where bb.i=a.i)
Output: file:/data/allison/tdw_src/src/qe/build/ql/tmp/1835471693/10000
4	4.0	NULL
2	2.0	2
query: explain with a as (select * from test_with_1),bb as (select i,b  from test_with_2),c as (select i,d,b from test_with_3) select * from a join bb on (a.i=bb.i) join c on (bb.i=c.i) where a.d>0 and c.b>0
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_JOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_2))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b))))) bb) (= (. (TOK_TABLE_OR_COL a) i) (. (TOK_TABLE_OR_COL bb) i))) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_3))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL d)) (TOK_SELEXPR (TOK_TABLE_OR_COL b))))) c) (= (. (TOK_TABLE_OR_COL bb) i) (. (TOK_TABLE_OR_COL c) i)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_WHERE (and (> (. (TOK_TABLE_OR_COL a) d) 0) (> (. (TOK_TABLE_OR_COL c) b) 0)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-0
    type:root stage;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Filter Operator
              predicate:
                  expr: (d > 0)
                  type: boolean
              Operator:              Select Operator
                expressions:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                outputColumnNames: _col0, _col1, _col2
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: +
                  output key names: reducesinkkey0
                  output value names: _col0, _col1, _col2
                  Map-reduce partition columns:
                        expr: _col0
                        type: int
                  tag: 0
                  value expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
        bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
              outputColumnNames: _col0, _col1
              Operator:              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: int
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: +
                output key names: reducesinkkey0
                output value names: _col0, _col1
                Map-reduce partition columns:
                      expr: _col0
                      type: int
                tag: 1
                value expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: bigint
        c:default_db/test_with_3 
          Operator:          TableScan
            alias: default_db/test_with_3
            Operator:            Filter Operator
              predicate:
                  expr: (b > 0)
                  type: boolean
              Operator:              Select Operator
                expressions:
                      expr: i
                      type: int
                      expr: d
                      type: double
                      expr: b
                      type: bigint
                outputColumnNames: _col0, _col1, _col2
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: +
                  output key names: reducesinkkey0
                  output value names: _col0, _col1, _col2
                  Map-reduce partition columns:
                        expr: _col0
                        type: int
                  tag: 2
                  value expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: double
                        expr: _col2
                        type: bigint
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [a:default_db/test_with_1]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb:default_db/test_with_2]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_3 [c:default_db/test_with_3]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
               Inner Join 1 to 2
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 {VALUE._col0} {VALUE._col1}
            2 {VALUE._col0} {VALUE._col1} {VALUE._col2}
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
          Operator:          Filter Operator
            predicate:
                expr: ((_col2 > 0) and (_col7 > 0))
                type: boolean
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
                    expr: _col3
                    type: int
                    expr: _col4
                    type: bigint
                    expr: _col5
                    type: int
                    expr: _col6
                    type: double
                    expr: _col7
                    type: bigint
              outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1

query: with a as (select * from test_with_1),bb as (select i,b  from test_with_2),c as (select i,d,b from test_with_3) select * from a join bb on (a.i=bb.i) join c on (bb.i=c.i) where a.d>0 and c.b>0
Output: file:/data/allison/tdw_src/src/qe/build/ql/tmp/286291164/10000
1	1	1.0	1	12	1	11.0	1
query: explain with a as (select * from test_with_1),bb as (select i,b,d  from test_with_2)  select a.b from a where exists (select * from bb where bb.i=a.i) group by a.b
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_LEFTSEMIJOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_2))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) bb) (= (. (TOK_TABLE_OR_COL bb) i) (. (TOK_TABLE_OR_COL a) i)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) b))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL a) b))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1;
  Stage-0
    type:root stage;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
              outputColumnNames: _col0, _col1
              Operator:              Reduce Output Operator
                key expressions:
                      expr: _col0
                      type: int
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: +
                output key names: reducesinkkey0
                output value names: _col1
                Map-reduce partition columns:
                      expr: _col0
                      type: int
                tag: 0
                value expressions:
                      expr: _col1
                      type: bigint
        bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
              outputColumnNames: _col0
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: int
                outputColumnNames: _col0
                Operator:                Group By Operator
                  keys:
                        expr: _col0
                        type: int
                  mode: hash
                  outputColumnNames: _col0
                  UseNewGroupBy: false
                  Operator:                  Reduce Output Operator
                    key expressions:
                          expr: _col0
                          type: int
                    key serialize infos:
                      table descs
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    sort order: +
                    output key names: reducesinkkey0
                    Map-reduce partition columns:
                          expr: _col0
                          type: int
                    tag: 1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [a:default_db/test_with_1]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col1}
            1 
          handleSkewJoin: false
          outputColumnNames: _col1
          Operator:          Select Operator
            expressions:
                  expr: _col1
                  type: bigint
            outputColumnNames: _col1
            Operator:            Group By Operator
              keys:
                    expr: _col1
                    type: bigint
              mode: hash
              outputColumnNames: _col0
              UseNewGroupBy: true
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1394353707/10002 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: ++
              output key names: _col0
              tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1394353707/10002 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/1394353707/10002]
      Reduce Operator Tree:
        Operator:        Group By Operator
          keys:
                expr: KEY._col0
                type: bigint
          mode: mergepartial
          outputColumnNames: _col0
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: bigint
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1

query: with a as (select * from test_with_1),bb as (select i,b,d  from test_with_2)  select a.b from a where exists (select * from bb where bb.i=a.i) group by a.b
Output: file:/data/allison/tdw_src/src/qe/build/ql/tmp/92486428/10000
NULL
1
3
query: explain insert into table test_with_3 (i,b,d)  with a as (select * from test_with_1),bb as (select * from test_with_2) select a.i, bb.b,bb.d from a,bb
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_2))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) bb))) (TOK_INSERT (TOK_APPENDDESTINATION (TOK_TABDEST (TOK_TAB test_with_3) (TOK_TABLE_OR_COL i) (TOK_TABLE_OR_COL b) (TOK_TABLE_OR_COL d))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) d)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-0
    type:;depends on:Stage-1;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
              outputColumnNames: _col0
              Operator:              Reduce Output Operator
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: 
                output value names: _col0
                tag: 0
                value expressions:
                      expr: _col0
                      type: int
        bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Select Operator
              expressions:
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: _col1, _col2
              Operator:              Reduce Output Operator
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: 
                output value names: _col1, _col2
                tag: 1
                value expressions:
                      expr: _col1
                      type: bigint
                      expr: _col2
                      type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [a:default_db/test_with_1]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0}
            1 {VALUE._col1} {VALUE._col2}
          handleSkewJoin: false
          outputColumnNames: _col0, _col4, _col5
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col4
                  type: bigint
                  expr: _col5
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 1
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: test_with_3

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

query: insert into table test_with_3 (i,b,d)  with a as (select * from test_with_1),bb as (select * from test_with_2) select a.i, bb.b,bb.d from a,bb
Output: default_db/test_with_3
query: explain insert overwrite into table test_with_3   with a as (select * from test_with_1),bb as (select * from test_with_2)  select * from a where exists (select * from bb where bb.i=a.i)  and a.d>0
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_LEFTSEMIJOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_2))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) bb) (= (. (TOK_TABLE_OR_COL bb) i) (. (TOK_TABLE_OR_COL a) i)))) (TOK_INSERT (TOK_DESTINATION (TOK_TABDEST (TOK_TAB test_with_3))) (TOK_SELECT (TOK_SELEXPR (TOK_ALLCOLREF a))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL a) d) 0))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-0
    type:;depends on:Stage-1;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Filter Operator
              predicate:
                  expr: (d > 0)
                  type: boolean
              Operator:              Select Operator
                expressions:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                outputColumnNames: _col0, _col1, _col2
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: +
                  output key names: reducesinkkey0
                  output value names: _col0, _col1, _col2
                  Map-reduce partition columns:
                        expr: _col0
                        type: int
                  tag: 0
                  value expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
        bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
              outputColumnNames: _col0
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: int
                outputColumnNames: _col0
                Operator:                Group By Operator
                  keys:
                        expr: _col0
                        type: int
                  mode: hash
                  outputColumnNames: _col0
                  UseNewGroupBy: false
                  Operator:                  Reduce Output Operator
                    key expressions:
                          expr: _col0
                          type: int
                    key serialize infos:
                      table descs
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    sort order: +
                    output key names: reducesinkkey0
                    Map-reduce partition columns:
                          expr: _col0
                          type: int
                    tag: 1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [a:default_db/test_with_1]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Operator:          Filter Operator
            predicate:
                expr: (_col2 > 0)
                type: boolean
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 1
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: test_with_3

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

query: insert overwrite into table test_with_3   with a as (select * from test_with_1),bb as (select * from test_with_2)  select * from a where exists (select * from bb where bb.i=a.i)  and a.d>0
Output: default_db/test_with_3
query: explain insert overwrite table test_with_3 select * from (select * from test_with_1) a  where exists (select * from (select * from test_with_2) bb where bb.i=a.i)  and a.d>0
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_LEFTSEMIJOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_2))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) bb) (= (. (TOK_TABLE_OR_COL bb) i) (. (TOK_TABLE_OR_COL a) i)))) (TOK_INSERT (TOK_DESTINATION (TOK_TABDEST (TOK_TAB test_with_3))) (TOK_SELECT (TOK_SELEXPR (TOK_ALLCOLREF a))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL a) d) 0))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-0
    type:;depends on:Stage-1;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Filter Operator
              predicate:
                  expr: (d > 0)
                  type: boolean
              Operator:              Select Operator
                expressions:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                outputColumnNames: _col0, _col1, _col2
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: +
                  output key names: reducesinkkey0
                  output value names: _col0, _col1, _col2
                  Map-reduce partition columns:
                        expr: _col0
                        type: int
                  tag: 0
                  value expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
        bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
              outputColumnNames: _col0
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: int
                outputColumnNames: _col0
                Operator:                Group By Operator
                  keys:
                        expr: _col0
                        type: int
                  mode: hash
                  outputColumnNames: _col0
                  UseNewGroupBy: false
                  Operator:                  Reduce Output Operator
                    key expressions:
                          expr: _col0
                          type: int
                    key serialize infos:
                      table descs
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    sort order: +
                    output key names: reducesinkkey0
                    Map-reduce partition columns:
                          expr: _col0
                          type: int
                    tag: 1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [a:default_db/test_with_1]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Operator:          Filter Operator
            predicate:
                expr: (_col2 > 0)
                type: boolean
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 1
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: test_with_3

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

query: explain with a as (select * from test_with_1),bb as (select i,b,d  from a ) select i from bb
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) bb)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-0
    type:root stage;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        bb:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
              outputColumnNames: _col0
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: int
                outputColumnNames: _col0
                Operator:                Select Operator
                  expressions:
                        expr: _col0
                        type: int
                  outputColumnNames: _col0
                  Operator:                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    table:
                      table descs
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [bb:a:default_db/test_with_1]

  Stage: Stage-0
    Fetch Operator
      limit: -1

query: with a as (select * from test_with_1),bb as (select i,b,d  from a ) select i from bb
Output: file:/data/allison/tdw_src/src/qe/build/ql/tmp/1557164758/10000
1
2
3
NULL
5
query: explain with a as (select * from test_with_1),bb as (select a.i,a.b,a.d from a left join test_with_2 union all select i,b,d from test_with_3) select sum(b) from bb group by bb.i
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_UNION (TOK_QUERY (TOK_FROM (TOK_LEFTOUTERJOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a) (TOK_TABREF (TOK_TAB test_with_2)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) d))))) (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_3))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d)))))) bb)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION sum (TOK_TABLE_OR_COL b)))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL bb) i))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1,Stage-4;
  Stage-4
    type:root stage;
  Stage-0
    type:root stage;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        null-subquery1:bb-subquery1:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              Reduce Output Operator
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: 
                output value names: _col0, _col1, _col2
                tag: 0
                value expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: bigint
                      expr: _col2
                      type: double
        null-subquery1:bb-subquery1:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              tag: 1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [null-subquery1:bb-subquery1:a:default_db/test_with_1]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [null-subquery1:bb-subquery1:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Left Outer Join0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/802519947/10002 
          Operator:          Union
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
              outputColumnNames: _col0, _col1
              Operator:              Group By Operator
                aggregations:
                      expr: sum(_col1)
                keys:
                      expr: _col0
                      type: int
                mode: hash
                outputColumnNames: _col0, _col1
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++
                  output key names: _col0, _col1
                  tag: -1
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/802519947/10003 
          Operator:          Union
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
              outputColumnNames: _col0, _col1
              Operator:              Group By Operator
                aggregations:
                      expr: sum(_col1)
                keys:
                      expr: _col0
                      type: int
                mode: hash
                outputColumnNames: _col0, _col1
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++
                  output key names: _col0, _col1
                  tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/802519947/10002 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/802519947/10002]
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/802519947/10003 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/802519947/10003]
      Reduce Operator Tree:
        Operator:        Group By Operator
          aggregations:
                expr: sum(KEY._col1:0._col0)
          keys:
                expr: KEY._col0
                type: int
          mode: mergepartial
          outputColumnNames: _col0, _col1
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-4
    Map Reduce
      Alias -> Map Operator Tree:
        null-subquery2:bb-subquery2:default_db/test_with_3 
          Operator:          TableScan
            alias: default_db/test_with_3
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_3 [null-subquery2:bb-subquery2:default_db/test_with_3]

  Stage: Stage-0
    Fetch Operator
      limit: -1

query: with a as (select * from test_with_1),bb as (select a.i,a.b,a.d from a left join test_with_2 union all select i,b,d from test_with_3) select sum(b) from bb group by bb.i
Output: file:/data/allison/tdw_src/src/qe/build/ql/tmp/1083757108/10000
20
6
10
18
NULL
query: explain INSERT INTO TABLE test_with_3(b,i) WITH a AS (SELECT i ni ,ROW_NUMBER() OVER ( ORDER BY b ) nb   FROM test_with_1  WHERE  d >= 0) ,bb AS ( select i,b from  ( SELECT  i ,b FROM test_with_2  WHERE EXISTS (  SELECT *  FROM test_with_1 WHERE test_with_1.i = test_with_2.i) UNION ALL  SELECT ni i ,nb b  FROM a ) tmpt ) SELECT i,b FROM bb
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_UNION (TOK_QUERY (TOK_FROM (TOK_LEFTSEMIJOIN (TOK_TABREF (TOK_TAB test_with_2)) (TOK_TABREF (TOK_TAB test_with_1)) (= (. (TOK_TABLE_OR_COL test_with_1) i) (. (TOK_TABLE_OR_COL test_with_2) i)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) b))))) (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i) ni) (TOK_SELEXPR (TOK_FUNCTIONOVER ROW_NUMBERover (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL b)))) nb)) (TOK_WHERE (>= (TOK_TABLE_OR_COL d) 0)))) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL ni) i) (TOK_SELEXPR (TOK_TABLE_OR_COL nb) b))))) tmpt)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b))))) bb)) (TOK_INSERT (TOK_APPENDDESTINATION (TOK_TABDEST (TOK_TAB test_with_3) (TOK_TABLE_OR_COL b) (TOK_TABLE_OR_COL i))) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1,Stage-7;
  Stage-5
    type:;depends on:Stage-2;consists of:Stage-4,Stage-3;
  Stage-4
    type:;
  Stage-0
    type:;depends on:Stage-4,Stage-3;
  Stage-3
    type:;
  Stage-7
    type:root stage;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        bb-subquery1:tmpt-subquery1:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Reduce Output Operator
              key expressions:
                    expr: i
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0, _col1
              Map-reduce partition columns:
                    expr: i
                    type: int
              tag: 0
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
        bb-subquery1:tmpt-subquery1:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
              outputColumnNames: i
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                mode: hash
                outputColumnNames: _col0
                UseNewGroupBy: false
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: +
                  output key names: reducesinkkey0
                  Map-reduce partition columns:
                        expr: _col0
                        type: int
                  tag: 1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb-subquery1:tmpt-subquery1:default_db/test_with_2]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [bb-subquery1:tmpt-subquery1:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0, _col1
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1323080377/10002 
          Operator:          Union
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
              outputColumnNames: _col0, _col1
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: bigint
                outputColumnNames: _col0, _col1
                Operator:                Select Operator
                  expressions:
                        expr: UDFToInteger(_col1)
                        type: int
                        expr: UDFToLong(_col0)
                        type: bigint
                        expr: null
                        type: void
                  outputColumnNames: _col0, _col1, _col2
                  Operator:                  File Output Operator
                    compressed: false
                    GlobalTableId: 1
                    table:
                      table descs
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: test_with_3
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1323080377/10004 
          Operator:          Union
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
              outputColumnNames: _col0, _col1
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: bigint
                outputColumnNames: _col0, _col1
                Operator:                Select Operator
                  expressions:
                        expr: UDFToInteger(_col1)
                        type: int
                        expr: UDFToLong(_col0)
                        type: bigint
                        expr: null
                        type: void
                  outputColumnNames: _col0, _col1, _col2
                  Operator:                  File Output Operator
                    compressed: false
                    GlobalTableId: 1
                    table:
                      table descs
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: test_with_3
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1323080377/10002 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/1323080377/10002]
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1323080377/10004 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/1323080377/10004]

  Stage: Stage-5
    Conditional Operator

  Stage: Stage-4
    Move Operator
      files:
          hdfs directory: true
          destination: file:/data/allison/tdw_src/src/qe/build/ql/tmp/920551992/10000

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1323080377/10003 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: rand()
                    type: double
              tag: -1
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1323080377/10003 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/1323080377/10003]
      Reduce Operator Tree:
        Operator:        Extract
          Operator:          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
              table descs
                input format: org.apache.hadoop.mapred.TextInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                name: test_with_3

  Stage: Stage-7
    Map Reduce
      Alias -> Map Operator Tree:
        bb-subquery2:tmpt-subquery2:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Filter Operator
              predicate:
                  expr: (d >= 0)
                  type: boolean
              Operator:              Reduce Output Operator
                key expressions:
                      expr: 1
                      type: int
                      expr: b
                      type: bigint
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: ++
                output key names: _col0, _col1
                output value names: _col0, _col1, _col2
                Map-reduce partition columns:
                      expr: 1
                      type: int
                tag: -1
                value expressions:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [bb-subquery2:tmpt-subquery2:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Analysis Operator
          Analysises:
                expr: row_numberover() OVER ( KEY._col1 )
          Distinct: false
          expr: row_numberover() OVER ( KEY._col1 )
          OrderByKeys:
                expr: KEY._col1
                type: bigint
          OtherColumns:
                expr: VALUE._col0
                type: int
          OutputColumnNames: _col0, _col1, _col3
          Operator:          Select Operator
            expressions:
                  expr: _col3
                  type: int
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0, _col1
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
              outputColumnNames: _col0, _col1
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

query: INSERT INTO TABLE test_with_3(b,i) WITH a AS (SELECT i ni ,ROW_NUMBER() OVER ( ORDER BY b ) nb   FROM test_with_1  WHERE  d >= 0) ,bb AS ( select i,b from  ( SELECT  i ,b FROM test_with_2  WHERE EXISTS (  SELECT *  FROM test_with_1 WHERE test_with_1.i = test_with_2.i) UNION ALL  SELECT ni i ,nb b  FROM a ) tmpt ) SELECT i,b FROM bb
Output: default_db/test_with_3
query: explain INSERT TABLE test_with_3( b ,i) SELECT i,b FROM (SELECT i,b  FROM (SELECT i ,b FROM test_with_2 WHERE EXISTS ( SELECT *  FROM test_with_1 WHERE test_with_1.i = test_with_2.i) UNION ALL SELECT ni i ,nb b FROM (SELECT i ni ,ROW_NUMBER() OVER ( ORDER BY b) nb FROM test_with_1 WHERE d >= 0) a) tmpt ) bb
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_UNION (TOK_QUERY (TOK_FROM (TOK_LEFTSEMIJOIN (TOK_TABREF (TOK_TAB test_with_2)) (TOK_TABREF (TOK_TAB test_with_1)) (= (. (TOK_TABLE_OR_COL test_with_1) i) (. (TOK_TABLE_OR_COL test_with_2) i)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) b))))) (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i) ni) (TOK_SELEXPR (TOK_FUNCTIONOVER ROW_NUMBERover (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL b)))) nb)) (TOK_WHERE (>= (TOK_TABLE_OR_COL d) 0)))) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL ni) i) (TOK_SELEXPR (TOK_TABLE_OR_COL nb) b))))) tmpt)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b))))) bb)) (TOK_INSERT (TOK_APPENDDESTINATION (TOK_TABDEST (TOK_TAB test_with_3) (TOK_TABLE_OR_COL b) (TOK_TABLE_OR_COL i))) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1,Stage-7;
  Stage-5
    type:;depends on:Stage-2;consists of:Stage-4,Stage-3;
  Stage-4
    type:;
  Stage-0
    type:;depends on:Stage-4,Stage-3;
  Stage-3
    type:;
  Stage-7
    type:root stage;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        bb-subquery1:tmpt-subquery1:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Reduce Output Operator
              key expressions:
                    expr: i
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0, _col1
              Map-reduce partition columns:
                    expr: i
                    type: int
              tag: 0
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
        bb-subquery1:tmpt-subquery1:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
              outputColumnNames: i
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                mode: hash
                outputColumnNames: _col0
                UseNewGroupBy: false
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: +
                  output key names: reducesinkkey0
                  Map-reduce partition columns:
                        expr: _col0
                        type: int
                  tag: 1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb-subquery1:tmpt-subquery1:default_db/test_with_2]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [bb-subquery1:tmpt-subquery1:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0, _col1
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1480753489/10002 
          Operator:          Union
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
              outputColumnNames: _col0, _col1
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: bigint
                outputColumnNames: _col0, _col1
                Operator:                Select Operator
                  expressions:
                        expr: UDFToInteger(_col1)
                        type: int
                        expr: UDFToLong(_col0)
                        type: bigint
                        expr: null
                        type: void
                  outputColumnNames: _col0, _col1, _col2
                  Operator:                  File Output Operator
                    compressed: false
                    GlobalTableId: 1
                    table:
                      table descs
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: test_with_3
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1480753489/10004 
          Operator:          Union
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
              outputColumnNames: _col0, _col1
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: bigint
                outputColumnNames: _col0, _col1
                Operator:                Select Operator
                  expressions:
                        expr: UDFToInteger(_col1)
                        type: int
                        expr: UDFToLong(_col0)
                        type: bigint
                        expr: null
                        type: void
                  outputColumnNames: _col0, _col1, _col2
                  Operator:                  File Output Operator
                    compressed: false
                    GlobalTableId: 1
                    table:
                      table descs
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: test_with_3
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1480753489/10002 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/1480753489/10002]
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1480753489/10004 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/1480753489/10004]

  Stage: Stage-5
    Conditional Operator

  Stage: Stage-4
    Move Operator
      files:
          hdfs directory: true
          destination: file:/data/allison/tdw_src/src/qe/build/ql/tmp/1970604771/10000

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1480753489/10003 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: rand()
                    type: double
              tag: -1
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1480753489/10003 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/1480753489/10003]
      Reduce Operator Tree:
        Operator:        Extract
          Operator:          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
              table descs
                input format: org.apache.hadoop.mapred.TextInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                name: test_with_3

  Stage: Stage-7
    Map Reduce
      Alias -> Map Operator Tree:
        bb-subquery2:tmpt-subquery2:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Filter Operator
              predicate:
                  expr: (d >= 0)
                  type: boolean
              Operator:              Reduce Output Operator
                key expressions:
                      expr: 1
                      type: int
                      expr: b
                      type: bigint
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                sort order: ++
                output key names: _col0, _col1
                output value names: _col0, _col1, _col2
                Map-reduce partition columns:
                      expr: 1
                      type: int
                tag: -1
                value expressions:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [bb-subquery2:tmpt-subquery2:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Analysis Operator
          Analysises:
                expr: row_numberover() OVER ( KEY._col1 )
          Distinct: false
          expr: row_numberover() OVER ( KEY._col1 )
          OrderByKeys:
                expr: KEY._col1
                type: bigint
          OtherColumns:
                expr: VALUE._col0
                type: int
          OutputColumnNames: _col0, _col1, _col3
          Operator:          Select Operator
            expressions:
                  expr: _col3
                  type: int
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0, _col1
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
              outputColumnNames: _col0, _col1
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

query: explain insert into table test_with_3 WITH a AS (SELECT distinct i,b,d FROM test_with_1) ,bb as (select a.i,a.b,a.d from test_with_2 join a),cc as (select bb.i,bb.b,bb.d from bb full join a on a.i=bb.i where a.i>0),dd as (select * from cc) select * from (select a.i,a.b,a.d from a join cc join (select * from dd) ff) ee
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_JOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECTDI (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_FULLOUTERJOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TAB test_with_2)) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECTDI (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) d))))) bb) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECTDI (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a) (= (. (TOK_TABLE_OR_COL a) i) (. (TOK_TABLE_OR_COL bb) i)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) d))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL a) i) 0)))) cc)) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_FULLOUTERJOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TAB test_with_2)) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECTDI (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) d))))) bb) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECTDI (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a) (= (. (TOK_TABLE_OR_COL a) i) (. (TOK_TABLE_OR_COL bb) i)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) d))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL a) i) 0)))) cc)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) dd)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) ff))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) d))))) ee)) (TOK_INSERT (TOK_APPENDDESTINATION (TOK_TABDEST (TOK_TAB test_with_3))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1,Stage-6;
  Stage-3
    type:;depends on:Stage-2,Stage-11;
  Stage-0
    type:;depends on:Stage-3;
  Stage-4
    type:root stage;
  Stage-5
    type:;depends on:Stage-4;
  Stage-6
    type:;depends on:Stage-5,Stage-8;
  Stage-8
    type:root stage;
  Stage-9
    type:root stage;
  Stage-10
    type:;depends on:Stage-9;
  Stage-11
    type:;depends on:Stage-10,Stage-13;
  Stage-13
    type:root stage;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        ee:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: i, b, d
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++++
                  output key names: _col0, _col1, _col2
                  tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [ee:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          keys:
                expr: KEY._col0
                type: int
                expr: KEY._col1
                type: bigint
                expr: KEY._col2
                type: double
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              output value names: _col0, _col1, _col2
              tag: 0
              value expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
        $INTNAME1 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              tag: 1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/757523217/10002 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/757523217/10006 [$INTNAME1]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Operator:          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
              table descs
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              output value names: _col0, _col1, _col2
              tag: 0
              value expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
        $INTNAME1 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              tag: 1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/757523217/10003 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/757523217/10010 [$INTNAME1]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 1
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: test_with_3

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

  Stage: Stage-4
    Map Reduce
      Alias -> Map Operator Tree:
        ee:cc:bb:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: i, b, d
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++++
                  output key names: _col0, _col1, _col2
                  tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [ee:cc:bb:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          keys:
                expr: KEY._col0
                type: int
                expr: KEY._col1
                type: bigint
                expr: KEY._col2
                type: double
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-5
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              output value names: _col0
              tag: 1
              value expressions:
                    expr: _col0
                    type: int
        ee:cc:bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              tag: 0
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/757523217/10004 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [ee:cc:bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col3
          Operator:          Select Operator
            expressions:
                  expr: _col3
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-6
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              Map-reduce partition columns:
                    expr: _col0
                    type: int
              tag: 0
        $INTNAME1 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0
              Map-reduce partition columns:
                    expr: _col0
                    type: int
              tag: 1
              value expressions:
                    expr: _col0
                    type: int
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/757523217/10005 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/757523217/10007 [$INTNAME1]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Outer Join 0 to 1
          condition expressions:
            0 
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col3
          Operator:          Filter Operator
            predicate:
                expr: (_col3 > 0)
                type: boolean
            Operator:            Select Operator
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-8
    Map Reduce
      Alias -> Map Operator Tree:
        ee:cc:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: i, b, d
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++++
                  output key names: _col0, _col1, _col2
                  tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [ee:cc:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          keys:
                expr: KEY._col0
                type: int
                expr: KEY._col1
                type: bigint
                expr: KEY._col2
                type: double
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-9
    Map Reduce
      Alias -> Map Operator Tree:
        ee:ff:dd:cc:bb:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: i, b, d
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++++
                  output key names: _col0, _col1, _col2
                  tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [ee:ff:dd:cc:bb:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          keys:
                expr: KEY._col0
                type: int
                expr: KEY._col1
                type: bigint
                expr: KEY._col2
                type: double
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-10
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              output value names: _col0
              tag: 1
              value expressions:
                    expr: _col0
                    type: int
        ee:ff:dd:cc:bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              tag: 0
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/757523217/10008 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [ee:ff:dd:cc:bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col3
          Operator:          Select Operator
            expressions:
                  expr: _col3
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-11
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              Map-reduce partition columns:
                    expr: _col0
                    type: int
              tag: 0
        $INTNAME1 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0
              Map-reduce partition columns:
                    expr: _col0
                    type: int
              tag: 1
              value expressions:
                    expr: _col0
                    type: int
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/757523217/10009 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/757523217/10011 [$INTNAME1]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Outer Join 0 to 1
          condition expressions:
            0 
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col3
          Operator:          Filter Operator
            predicate:
                expr: (_col3 > 0)
                type: boolean
            Operator:            Select Operator
              Operator:              Select Operator
                Operator:                Select Operator
                  Operator:                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    table:
                      table descs
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-13
    Map Reduce
      Alias -> Map Operator Tree:
        ee:ff:dd:cc:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: i, b, d
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++++
                  output key names: _col0, _col1, _col2
                  tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [ee:ff:dd:cc:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          keys:
                expr: KEY._col0
                type: int
                expr: KEY._col1
                type: bigint
                expr: KEY._col2
                type: double
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

query: insert into table test_with_3 WITH a AS (SELECT distinct i,b,d FROM test_with_1) ,bb as (select a.i,a.b,a.d from test_with_2 join a),cc as (select bb.i,bb.b,bb.d from bb full join a on a.i=bb.i where a.i>0),dd as (select * from cc) select * from (select a.i,a.b,a.d from a join cc join (select * from dd) ff) ee
Output: default_db/test_with_3
query: explain insert table test_with_3 select * from (select a.i,a.b,a.d from (SELECT distinct i ,b, d FROM test_with_1) a join (select bb.i,bb.b,bb.d from (select a.i,a.b,a.d from test_with_2 join (SELECT distinct i,b,d FROM test_with_1) a) bb full join (SELECT distinct i, b, d FROM test_with_1) a on a.i=bb.i where a.i>0) cc join (select * from (select * from (select bb.i,bb.b,bb.d from (select a.i,a.b,a.d from test_with_2 join (SELECT distinct i,b, d FROM test_with_1) a) bb full join (SELECT distinct i,b,d FROM test_with_1) a on a.i=bb.i where a.i>0) cc)  dd) ff) ee
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_JOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECTDI (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_FULLOUTERJOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TAB test_with_2)) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECTDI (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) d))))) bb) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECTDI (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a) (= (. (TOK_TABLE_OR_COL a) i) (. (TOK_TABLE_OR_COL bb) i)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) d))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL a) i) 0)))) cc)) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_FULLOUTERJOIN (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TAB test_with_2)) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECTDI (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) d))))) bb) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECTDI (TOK_SELEXPR (TOK_TABLE_OR_COL i)) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a) (= (. (TOK_TABLE_OR_COL a) i) (. (TOK_TABLE_OR_COL bb) i)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) d))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL a) i) 0)))) cc)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) dd)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) ff))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) d))))) ee)) (TOK_INSERT (TOK_APPENDDESTINATION (TOK_TABDEST (TOK_TAB test_with_3))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1,Stage-6;
  Stage-3
    type:;depends on:Stage-2,Stage-11;
  Stage-0
    type:;depends on:Stage-3;
  Stage-4
    type:root stage;
  Stage-5
    type:;depends on:Stage-4;
  Stage-6
    type:;depends on:Stage-5,Stage-8;
  Stage-8
    type:root stage;
  Stage-9
    type:root stage;
  Stage-10
    type:;depends on:Stage-9;
  Stage-11
    type:;depends on:Stage-10,Stage-13;
  Stage-13
    type:root stage;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        ee:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: i, b, d
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++++
                  output key names: _col0, _col1, _col2
                  tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [ee:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          keys:
                expr: KEY._col0
                type: int
                expr: KEY._col1
                type: bigint
                expr: KEY._col2
                type: double
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              output value names: _col0, _col1, _col2
              tag: 0
              value expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
        $INTNAME1 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              tag: 1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/214119599/10002 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/214119599/10006 [$INTNAME1]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Operator:          File Output Operator
            compressed: false
            GlobalTableId: 0
            table:
              table descs
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              output value names: _col0, _col1, _col2
              tag: 0
              value expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
        $INTNAME1 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              tag: 1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/214119599/10003 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/214119599/10010 [$INTNAME1]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 1
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: test_with_3

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

  Stage: Stage-4
    Map Reduce
      Alias -> Map Operator Tree:
        ee:cc:bb:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: i, b, d
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++++
                  output key names: _col0, _col1, _col2
                  tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [ee:cc:bb:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          keys:
                expr: KEY._col0
                type: int
                expr: KEY._col1
                type: bigint
                expr: KEY._col2
                type: double
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-5
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              output value names: _col0
              tag: 1
              value expressions:
                    expr: _col0
                    type: int
        ee:cc:bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              tag: 0
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/214119599/10004 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [ee:cc:bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col3
          Operator:          Select Operator
            expressions:
                  expr: _col3
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-6
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              Map-reduce partition columns:
                    expr: _col0
                    type: int
              tag: 0
        $INTNAME1 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0
              Map-reduce partition columns:
                    expr: _col0
                    type: int
              tag: 1
              value expressions:
                    expr: _col0
                    type: int
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/214119599/10005 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/214119599/10007 [$INTNAME1]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Outer Join 0 to 1
          condition expressions:
            0 
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col3
          Operator:          Filter Operator
            predicate:
                expr: (_col3 > 0)
                type: boolean
            Operator:            Select Operator
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-8
    Map Reduce
      Alias -> Map Operator Tree:
        ee:cc:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: i, b, d
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++++
                  output key names: _col0, _col1, _col2
                  tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [ee:cc:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          keys:
                expr: KEY._col0
                type: int
                expr: KEY._col1
                type: bigint
                expr: KEY._col2
                type: double
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-9
    Map Reduce
      Alias -> Map Operator Tree:
        ee:ff:dd:cc:bb:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: i, b, d
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++++
                  output key names: _col0, _col1, _col2
                  tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [ee:ff:dd:cc:bb:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          keys:
                expr: KEY._col0
                type: int
                expr: KEY._col1
                type: bigint
                expr: KEY._col2
                type: double
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-10
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              output value names: _col0
              tag: 1
              value expressions:
                    expr: _col0
                    type: int
        ee:ff:dd:cc:bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Reduce Output Operator
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: 
              tag: 0
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/214119599/10008 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [ee:ff:dd:cc:bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col3
          Operator:          Select Operator
            expressions:
                  expr: _col3
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-11
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              Map-reduce partition columns:
                    expr: _col0
                    type: int
              tag: 0
        $INTNAME1 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0
              Map-reduce partition columns:
                    expr: _col0
                    type: int
              tag: 1
              value expressions:
                    expr: _col0
                    type: int
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/214119599/10009 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/214119599/10011 [$INTNAME1]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Outer Join 0 to 1
          condition expressions:
            0 
            1 {VALUE._col0}
          handleSkewJoin: false
          outputColumnNames: _col3
          Operator:          Filter Operator
            predicate:
                expr: (_col3 > 0)
                type: boolean
            Operator:            Select Operator
              Operator:              Select Operator
                Operator:                Select Operator
                  Operator:                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    table:
                      table descs
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-13
    Map Reduce
      Alias -> Map Operator Tree:
        ee:ff:dd:cc:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Select Operator
              expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
              outputColumnNames: i, b, d
              Operator:              Group By Operator
                keys:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                UseNewGroupBy: true
                Operator:                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: bigint
                        expr: _col2
                        type: double
                  key serialize infos:
                    table descs
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  sort order: ++++
                  output key names: _col0, _col1, _col2
                  tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [ee:ff:dd:cc:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          keys:
                expr: KEY._col0
                type: int
                expr: KEY._col1
                type: bigint
                expr: KEY._col2
                type: double
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
            outputColumnNames: _col0
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

query: explain insert into table test_with_3 WITH a AS (SELECT ROW_NUMBER () OVER (partition by i order by b) ii ,b,d FROM test_with_1),bb as (select test_with_2.i,test_with_2.b,test_with_2.d  from test_with_2 join a on a.b=test_with_2.b) select bb.i,bb.b,bb.d from bb where bb.i between 1 and 100
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TAB test_with_2)) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONOVER ROW_NUMBERover (TOK_PARTITIONBY (TOK_TABLE_OR_COL i)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL b)))) ii) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a) (= (. (TOK_TABLE_OR_COL a) b) (. (TOK_TABLE_OR_COL test_with_2) b)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) d))))) bb)) (TOK_INSERT (TOK_APPENDDESTINATION (TOK_TABDEST (TOK_TAB test_with_3))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) d))) (TOK_WHERE (and (>= (. (TOK_TABLE_OR_COL bb) i) 1) (<= (. (TOK_TABLE_OR_COL bb) i) 100)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1;
  Stage-0
    type:;depends on:Stage-2;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        bb:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Reduce Output Operator
              key expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: ++
              output key names: _col0, _col1
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: i
                    type: int
              tag: -1
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [bb:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Analysis Operator
          Analysises:
                expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          Distinct: false
          expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          OrderByKeys:
                expr: KEY._col1
                type: bigint
          OutputColumnNames: _col0, _col1
          PartitionByKeys:
                expr: KEY._col0
                type: int
          Operator:          Select Operator
            expressions:
                  expr: _col1
                  type: bigint
            outputColumnNames: _col1
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col1
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              Map-reduce partition columns:
                    expr: _col1
                    type: bigint
              tag: 1
        bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Reduce Output Operator
              key expressions:
                    expr: b
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: b
                    type: bigint
              tag: 0
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1395014807/10002 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Filter Operator
              predicate:
                  expr: ((_col0 >= 1) and (_col0 <= 100))
                  type: boolean
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: bigint
                      expr: _col2
                      type: double
                outputColumnNames: _col0, _col1, _col2
                Operator:                File Output Operator
                  compressed: false
                  GlobalTableId: 1
                  table:
                    table descs
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: test_with_3

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

query: insert into table test_with_3 WITH a AS (SELECT ROW_NUMBER () OVER (partition by i order by b) ii ,b,d FROM test_with_1),bb as (select test_with_2.i,test_with_2.b,test_with_2.d  from test_with_2 join a on a.b=test_with_2.b) select bb.i,bb.b,bb.d from bb where bb.i between 1 and 100
Output: default_db/test_with_3
query: explain insert table test_with_3  select bb.i,bb.b,bb.d from (select test_with_2.i,test_with_2.b,test_with_2.d  from test_with_2 join (SELECT ROW_NUMBER () OVER (partition by i order by b) ii ,b,d FROM test_with_1)a on a.b=test_with_2.b) bb where bb.i between 1 and 100
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TAB test_with_2)) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONOVER ROW_NUMBERover (TOK_PARTITIONBY (TOK_TABLE_OR_COL i)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL b)))) ii) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a) (= (. (TOK_TABLE_OR_COL a) b) (. (TOK_TABLE_OR_COL test_with_2) b)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) d))))) bb)) (TOK_INSERT (TOK_APPENDDESTINATION (TOK_TABDEST (TOK_TAB test_with_3))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) d))) (TOK_WHERE (and (>= (. (TOK_TABLE_OR_COL bb) i) 1) (<= (. (TOK_TABLE_OR_COL bb) i) 100)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1;
  Stage-0
    type:;depends on:Stage-2;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        bb:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Reduce Output Operator
              key expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: ++
              output key names: _col0, _col1
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: i
                    type: int
              tag: -1
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [bb:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Analysis Operator
          Analysises:
                expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          Distinct: false
          expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          OrderByKeys:
                expr: KEY._col1
                type: bigint
          OutputColumnNames: _col0, _col1
          PartitionByKeys:
                expr: KEY._col0
                type: int
          Operator:          Select Operator
            expressions:
                  expr: _col1
                  type: bigint
            outputColumnNames: _col1
            Operator:            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col1
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              Map-reduce partition columns:
                    expr: _col1
                    type: bigint
              tag: 1
        bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Reduce Output Operator
              key expressions:
                    expr: b
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: b
                    type: bigint
              tag: 0
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/2020691815/10002 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Filter Operator
              predicate:
                  expr: ((_col0 >= 1) and (_col0 <= 100))
                  type: boolean
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: bigint
                      expr: _col2
                      type: double
                outputColumnNames: _col0, _col1, _col2
                Operator:                File Output Operator
                  compressed: false
                  GlobalTableId: 1
                  table:
                    table descs
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: test_with_3

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

query: explain insert into table test_with_3 WITH a AS (SELECT ROW_NUMBER () OVER (partition by i order by b) ii ,b,d FROM test_with_1),bb as (select test_with_2.i,test_with_2.b,test_with_2.d from test_with_2 where exists (select a.i,a.b,a.d from a where a.b=test_with_2.b and a.b between 1 and 100)) select bb.i,bb.b,bb.d from bb order by bb.i
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_LEFTSEMIJOIN (TOK_TABREF (TOK_TAB test_with_2)) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONOVER ROW_NUMBERover (TOK_PARTITIONBY (TOK_TABLE_OR_COL i)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL b)))) ii) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a) (and (= (. (TOK_TABLE_OR_COL a) b) (. (TOK_TABLE_OR_COL test_with_2) b)) (and (>= (. (TOK_TABLE_OR_COL a) b) 1) (<= (. (TOK_TABLE_OR_COL a) b) 100))))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) d))))) bb)) (TOK_INSERT (TOK_APPENDDESTINATION (TOK_TABDEST (TOK_TAB test_with_3))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) d))) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (. (TOK_TABLE_OR_COL bb) i)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1;
  Stage-3
    type:;depends on:Stage-2;
  Stage-0
    type:;depends on:Stage-3;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        bb:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Reduce Output Operator
              key expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: ++
              output key names: _col0, _col1
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: i
                    type: int
              tag: -1
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [bb:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Analysis Operator
          Analysises:
                expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          Distinct: false
          expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          OrderByKeys:
                expr: KEY._col1
                type: bigint
          OutputColumnNames: _col0, _col1
          PartitionByKeys:
                expr: KEY._col0
                type: int
          Operator:          Select Operator
            expressions:
                  expr: _col1
                  type: bigint
            outputColumnNames: _col1
            Operator:            Filter Operator
              predicate:
                  expr: (_col1 >= 1)
                  type: boolean
              Operator:              Filter Operator
                predicate:
                    expr: (_col1 <= 100)
                    type: boolean
                Operator:                Select Operator
                  expressions:
                        expr: _col1
                        type: bigint
                  outputColumnNames: _col1
                  Operator:                  Group By Operator
                    keys:
                          expr: _col1
                          type: bigint
                          expr: _col1
                          type: bigint
                          expr: _col1
                          type: bigint
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2
                    UseNewGroupBy: false
                    Operator:                    File Output Operator
                      compressed: false
                      GlobalTableId: 0
                      table:
                        table descs
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col2
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              Map-reduce partition columns:
                    expr: _col2
                    type: bigint
              tag: 1
        bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Reduce Output Operator
              key expressions:
                    expr: b
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: b
                    type: bigint
              tag: 0
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1279972889/10002 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1279972889/10003 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0, _col1, _col2
              tag: -1
              value expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1279972889/10003 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/1279972889/10003]
      Reduce Operator Tree:
        Operator:        Extract
          Operator:          File Output Operator
            compressed: false
            GlobalTableId: 1
            table:
              table descs
                input format: org.apache.hadoop.mapred.TextInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                name: test_with_3

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

query: insert into table test_with_3 WITH a AS (SELECT ROW_NUMBER () OVER (partition by i order by b) ii ,b,d FROM test_with_1),bb as (select test_with_2.i,test_with_2.b,test_with_2.d from test_with_2 where exists (select a.i,a.b,a.d from a where a.b=test_with_2.b and a.b between 1 and 100)) select bb.i,bb.b,bb.d from bb order by bb.i
Output: default_db/test_with_3
query: explain insert table test_with_3  select bb.i,bb.b,bb.d from  (select test_with_2.i,test_with_2.b,test_with_2.d  from test_with_2 where exists (select a.ii,a.b,a.d from (SELECT ROW_NUMBER () OVER (partition by i order by b) ii,b,d FROM test_with_1) a where a.b=test_with_2.b and a.b between 1 and 100)) bb order by i
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_LEFTSEMIJOIN (TOK_TABREF (TOK_TAB test_with_2)) (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONOVER ROW_NUMBERover (TOK_PARTITIONBY (TOK_TABLE_OR_COL i)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL b)))) ii) (TOK_SELEXPR (TOK_TABLE_OR_COL b)) (TOK_SELEXPR (TOK_TABLE_OR_COL d))))) a) (and (= (. (TOK_TABLE_OR_COL a) b) (. (TOK_TABLE_OR_COL test_with_2) b)) (and (>= (. (TOK_TABLE_OR_COL a) b) 1) (<= (. (TOK_TABLE_OR_COL a) b) 100))))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL test_with_2) d))))) bb)) (TOK_INSERT (TOK_APPENDDESTINATION (TOK_TABDEST (TOK_TAB test_with_3))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) i)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) b)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bb) d))) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL i)))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1;
  Stage-3
    type:;depends on:Stage-2;
  Stage-0
    type:;depends on:Stage-3;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        bb:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Reduce Output Operator
              key expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: ++
              output key names: _col0, _col1
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: i
                    type: int
              tag: -1
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [bb:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Analysis Operator
          Analysises:
                expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          Distinct: false
          expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          OrderByKeys:
                expr: KEY._col1
                type: bigint
          OutputColumnNames: _col0, _col1
          PartitionByKeys:
                expr: KEY._col0
                type: int
          Operator:          Select Operator
            expressions:
                  expr: _col1
                  type: bigint
            outputColumnNames: _col1
            Operator:            Filter Operator
              predicate:
                  expr: (_col1 >= 1)
                  type: boolean
              Operator:              Filter Operator
                predicate:
                    expr: (_col1 <= 100)
                    type: boolean
                Operator:                Select Operator
                  expressions:
                        expr: _col1
                        type: bigint
                  outputColumnNames: _col1
                  Operator:                  Group By Operator
                    keys:
                          expr: _col1
                          type: bigint
                          expr: _col1
                          type: bigint
                          expr: _col1
                          type: bigint
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2
                    UseNewGroupBy: false
                    Operator:                    File Output Operator
                      compressed: false
                      GlobalTableId: 0
                      table:
                        table descs
                          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        $INTNAME 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col2
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              Map-reduce partition columns:
                    expr: _col2
                    type: bigint
              tag: 1
        bb:default_db/test_with_2 
          Operator:          TableScan
            alias: default_db/test_with_2
            Operator:            Reduce Output Operator
              key expressions:
                    expr: b
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: b
                    type: bigint
              tag: 0
              value expressions:
                    expr: i
                    type: int
                    expr: b
                    type: bigint
                    expr: d
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1786984322/10002 [$INTNAME]
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_2 [bb:default_db/test_with_2]
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Left Semi Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col1} {VALUE._col2}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0, _col1, _col2
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1786984322/10003 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +
              output key names: reducesinkkey0
              output value names: _col0, _col1, _col2
              tag: -1
              value expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/1786984322/10003 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/1786984322/10003]
      Reduce Operator Tree:
        Operator:        Extract
          Operator:          File Output Operator
            compressed: false
            GlobalTableId: 1
            table:
              table descs
                input format: org.apache.hadoop.mapred.TextInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                name: test_with_3

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

query: explain insert into table test_with_3 WITH a AS (select i ii,sum(b) bb,sum(d) dd from test_with_1 where i >0 group by i),bbb as ( select  ROW_NUMBER () OVER (partition by ii order by bb) iii,bb,dd from a where dd between 0 and 1000 ) select bbb.iii,bbb.bb,sum(bbb.dd) from bbb where bbb.iii>0 group by iii,bb
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i) ii) (TOK_SELEXPR (TOK_FUNCTION sum (TOK_TABLE_OR_COL b)) bb) (TOK_SELEXPR (TOK_FUNCTION sum (TOK_TABLE_OR_COL d)) dd)) (TOK_WHERE (> (TOK_TABLE_OR_COL i) 0)) (TOK_GROUPBY (TOK_TABLE_OR_COL i)))) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONOVER ROW_NUMBERover (TOK_PARTITIONBY (TOK_TABLE_OR_COL ii)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL bb)))) iii) (TOK_SELEXPR (TOK_TABLE_OR_COL bb)) (TOK_SELEXPR (TOK_TABLE_OR_COL dd))) (TOK_WHERE (and (>= (TOK_TABLE_OR_COL dd) 0) (<= (TOK_TABLE_OR_COL dd) 1000))))) bbb)) (TOK_INSERT (TOK_APPENDDESTINATION (TOK_TABDEST (TOK_TAB test_with_3))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL bbb) iii)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bbb) bb)) (TOK_SELEXPR (TOK_FUNCTION sum (. (TOK_TABLE_OR_COL bbb) dd)))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL bbb) iii) 0)) (TOK_GROUPBY (TOK_TABLE_OR_COL iii) (TOK_TABLE_OR_COL bb))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1;
  Stage-3
    type:;depends on:Stage-2;
  Stage-0
    type:;depends on:Stage-3;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        bbb:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Filter Operator
              predicate:
                  expr: (i > 0)
                  type: boolean
              Operator:              Select Operator
                expressions:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                outputColumnNames: i, b, d
                Operator:                Group By Operator
                  aggregations:
                        expr: sum(b)
                        expr: sum(d)
                  keys:
                        expr: i
                        type: int
                  mode: hash
                  outputColumnNames: _col0, _col1
                  UseNewGroupBy: true
                  Operator:                  Reduce Output Operator
                    key expressions:
                          expr: _col0
                          type: int
                    key serialize infos:
                      table descs
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    sort order: ++
                    output key names: _col0, _col1
                    tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [bbb:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          aggregations:
                expr: sum(KEY._col1:0._col0)
                expr: sum(KEY._col1:0._col1)
          keys:
                expr: KEY._col0
                type: int
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Filter Operator
              predicate:
                  expr: ((_col2 >= 0) and (_col2 <= 1000))
                  type: boolean
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/811053736/10002 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: ++
              output key names: _col0, _col1
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: _col0
                    type: int
              tag: -1
              value expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/811053736/10002 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/811053736/10002]
      Reduce Operator Tree:
        Operator:        Analysis Operator
          Analysises:
                expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          Distinct: false
          expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          OrderByKeys:
                expr: KEY._col1
                type: bigint
          OtherColumns:
                expr: VALUE._col2
                type: double
          OutputColumnNames: _col0, _col1, _col2, _col5
          PartitionByKeys:
                expr: KEY._col0
                type: int
          Operator:          Select Operator
            expressions:
                  expr: _col2
                  type: bigint
                  expr: _col1
                  type: bigint
                  expr: _col5
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Filter Operator
              predicate:
                  expr: (_col0 > 0)
                  type: boolean
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: bigint
                      expr: _col1
                      type: bigint
                      expr: _col2
                      type: double
                outputColumnNames: _col0, _col1, _col2
                Operator:                Group By Operator
                  aggregations:
                        expr: sum(_col2)
                  keys:
                        expr: _col0
                        type: bigint
                        expr: _col1
                        type: bigint
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2
                  UseNewGroupBy: true
                  Operator:                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    table:
                      table descs
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/811053736/10003 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: bigint
                    expr: _col1
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +++
              output key names: _col0, _col1, _col2
              tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/811053736/10003 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/811053736/10003]
      Reduce Operator Tree:
        Operator:        Group By Operator
          aggregations:
                expr: sum(KEY._col2:0._col0)
          keys:
                expr: KEY._col0
                type: bigint
                expr: KEY._col1
                type: bigint
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: bigint
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Select Operator
              expressions:
                    expr: UDFToInteger(_col0)
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 1
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: test_with_3

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

query: insert into table test_with_3 WITH a AS (select i ii,sum(b) bb,sum(d) dd from test_with_1 where i >0 group by i),bbb as ( select  ROW_NUMBER () OVER (partition by ii order by bb) iii,bb,dd from a where dd between 0 and 1000 ) select bbb.iii,bbb.bb,sum(bbb.dd) from bbb where bbb.iii>0 group by iii,bb
Output: default_db/test_with_3
query: explain insert table test_with_3  select bbb.iii,bbb.bb,sum(bbb.dd) from ( select ROW_NUMBER () OVER (partition by ii order by bb) iii,bb,dd from (select i ii,sum(b) bb,sum(d) dd from test_with_1 where i >0 group by i) a where dd between 0 and 1000 ) bbb where bbb.iii>0 group by iii,bb
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TAB test_with_1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL i) ii) (TOK_SELEXPR (TOK_FUNCTION sum (TOK_TABLE_OR_COL b)) bb) (TOK_SELEXPR (TOK_FUNCTION sum (TOK_TABLE_OR_COL d)) dd)) (TOK_WHERE (> (TOK_TABLE_OR_COL i) 0)) (TOK_GROUPBY (TOK_TABLE_OR_COL i)))) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTIONOVER ROW_NUMBERover (TOK_PARTITIONBY (TOK_TABLE_OR_COL ii)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL bb)))) iii) (TOK_SELEXPR (TOK_TABLE_OR_COL bb)) (TOK_SELEXPR (TOK_TABLE_OR_COL dd))) (TOK_WHERE (and (>= (TOK_TABLE_OR_COL dd) 0) (<= (TOK_TABLE_OR_COL dd) 1000))))) bbb)) (TOK_INSERT (TOK_APPENDDESTINATION (TOK_TABDEST (TOK_TAB test_with_3))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL bbb) iii)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL bbb) bb)) (TOK_SELEXPR (TOK_FUNCTION sum (. (TOK_TABLE_OR_COL bbb) dd)))) (TOK_WHERE (> (. (TOK_TABLE_OR_COL bbb) iii) 0)) (TOK_GROUPBY (TOK_TABLE_OR_COL iii) (TOK_TABLE_OR_COL bb))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-2
    type:;depends on:Stage-1;
  Stage-3
    type:;depends on:Stage-2;
  Stage-0
    type:;depends on:Stage-3;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        bbb:a:default_db/test_with_1 
          Operator:          TableScan
            alias: default_db/test_with_1
            Operator:            Filter Operator
              predicate:
                  expr: (i > 0)
                  type: boolean
              Operator:              Select Operator
                expressions:
                      expr: i
                      type: int
                      expr: b
                      type: bigint
                      expr: d
                      type: double
                outputColumnNames: i, b, d
                Operator:                Group By Operator
                  aggregations:
                        expr: sum(b)
                        expr: sum(d)
                  keys:
                        expr: i
                        type: int
                  mode: hash
                  outputColumnNames: _col0, _col1
                  UseNewGroupBy: true
                  Operator:                  Reduce Output Operator
                    key expressions:
                          expr: _col0
                          type: int
                    key serialize infos:
                      table descs
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    sort order: ++
                    output key names: _col0, _col1
                    tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/test/data/warehouse/default_db/test_with_1 [bbb:a:default_db/test_with_1]
      Reduce Operator Tree:
        Operator:        Group By Operator
          aggregations:
                expr: sum(KEY._col1:0._col0)
                expr: sum(KEY._col1:0._col1)
          keys:
                expr: KEY._col0
                type: int
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: int
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Filter Operator
              predicate:
                  expr: ((_col2 >= 0) and (_col2 <= 1000))
                  type: boolean
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/871006395/10002 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: ++
              output key names: _col0, _col1
              output value names: _col0, _col1, _col2
              Map-reduce partition columns:
                    expr: _col0
                    type: int
              tag: -1
              value expressions:
                    expr: _col0
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/871006395/10002 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/871006395/10002]
      Reduce Operator Tree:
        Operator:        Analysis Operator
          Analysises:
                expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          Distinct: false
          expr: row_numberover() OVER (KEY._col0 KEY._col1 )
          OrderByKeys:
                expr: KEY._col1
                type: bigint
          OtherColumns:
                expr: VALUE._col2
                type: double
          OutputColumnNames: _col0, _col1, _col2, _col5
          PartitionByKeys:
                expr: KEY._col0
                type: int
          Operator:          Select Operator
            expressions:
                  expr: _col2
                  type: bigint
                  expr: _col1
                  type: bigint
                  expr: _col5
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Filter Operator
              predicate:
                  expr: (_col0 > 0)
                  type: boolean
              Operator:              Select Operator
                expressions:
                      expr: _col0
                      type: bigint
                      expr: _col1
                      type: bigint
                      expr: _col2
                      type: double
                outputColumnNames: _col0, _col1, _col2
                Operator:                Group By Operator
                  aggregations:
                        expr: sum(_col2)
                  keys:
                        expr: _col0
                        type: bigint
                        expr: _col1
                        type: bigint
                  mode: hash
                  outputColumnNames: _col0, _col1, _col2
                  UseNewGroupBy: true
                  Operator:                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    table:
                      table descs
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/871006395/10003 
            Operator:            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: bigint
                    expr: _col1
                    type: bigint
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              sort order: +++
              output key names: _col0, _col1, _col2
              tag: -1
      Path -> Alias:
        file:/data/allison/tdw_src/src/qe/build/ql/tmp/871006395/10003 [file:/data/allison/tdw_src/src/qe/build/ql/tmp/871006395/10003]
      Reduce Operator Tree:
        Operator:        Group By Operator
          aggregations:
                expr: sum(KEY._col2:0._col0)
          keys:
                expr: KEY._col0
                type: bigint
                expr: KEY._col1
                type: bigint
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          UseNewGroupBy: true
          Operator:          Select Operator
            expressions:
                  expr: _col0
                  type: bigint
                  expr: _col1
                  type: bigint
                  expr: _col2
                  type: double
            outputColumnNames: _col0, _col1, _col2
            Operator:            Select Operator
              expressions:
                    expr: UDFToInteger(_col0)
                    type: int
                    expr: _col1
                    type: bigint
                    expr: _col2
                    type: double
              outputColumnNames: _col0, _col1, _col2
              Operator:              File Output Operator
                compressed: false
                GlobalTableId: 1
                table:
                  table descs
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: test_with_3

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_with_3

query: 
query: 
query: 
query: 
query: 
query: 
query: 
query: 
